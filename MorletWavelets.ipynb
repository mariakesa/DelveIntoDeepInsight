{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#!pip install git+https://github.com/aaren/wavelets\n",
    "#!pip install scipy==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data matrix, neurons by timepoints: (18795, 30766)\n",
      "(18795, 30560)\n"
     ]
    }
   ],
   "source": [
    "data_path='/media/maria/DATA1/Documents/data_for_suite2p/TX39/'\n",
    "dt=1\n",
    "spks= np.load(data_path+'spks.npy')\n",
    "print('Shape of the data matrix, neurons by timepoints:',spks.shape)\n",
    "iframe = np.load(data_path+'iframe.npy') # iframe[n] is the microscope frame for the image frame n\n",
    "ivalid = iframe+dt<spks.shape[-1] # remove timepoints outside the valid time range\n",
    "iframe = iframe[ivalid]\n",
    "S = spks[:, iframe+dt]\n",
    "print(S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DeepInsight Toolbox\n",
    "Â© Markus Frey\n",
    "https://github.com/CYHSM/DeepInsight\n",
    "Licensed under MIT License\n",
    "\"\"\"\n",
    "from wavelets import WaveletAnalysis\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def wavelet_transform(signal, sampling_rate, average_window=1000, scaling_factor=0.25, wave_highpass=2, wave_lowpass=30000):\n",
    "    \"\"\"\n",
    "    Calculates the wavelet transform for each point in signal, then averages\n",
    "    each window and returns together fourier frequencies\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : (N,1) array_like\n",
    "        Signal to be transformed\n",
    "    sampling_rate : int\n",
    "        Sampling rate of signal\n",
    "    average_window : int, optional\n",
    "        Average window to downsample wavelet transformed input, by default 1000\n",
    "    scaling_factor : float, optional\n",
    "        Determines amount of log-spaced frequencies M in output, by default 0.25\n",
    "    wave_highpass : int, optional\n",
    "        Cut of frequencies below, by default 2\n",
    "    wave_lowpass : int, optional\n",
    "        Cut of frequencies above, by default 30000\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    wavelet_power : (N, M) array_like\n",
    "        Wavelet transformed signal\n",
    "    wavelet_frequencies : (M, 1) array_like\n",
    "        Corresponding frequencies to wavelet_power\n",
    "    \"\"\"\n",
    "    (wavelet_power, wavelet_frequencies, wavelet_obj) = simple_wavelet_transform(signal, sampling_rate,\n",
    "                                                                                 scaling_factor=scaling_factor, wave_highpass=wave_highpass, wave_lowpass=wave_lowpass)\n",
    "\n",
    "    # Average over window\n",
    "    if average_window is not 1:\n",
    "        wavelet_power = np.reshape(\n",
    "            wavelet_power, (wavelet_power.shape[0], wavelet_power.shape[1] // average_window, average_window))\n",
    "        wavelet_power = np.mean(wavelet_power, axis=2).transpose()\n",
    "    else:\n",
    "        wavelet_power = wavelet_power.transpose()\n",
    "\n",
    "    return wavelet_power, wavelet_frequencies\n",
    "\n",
    "\n",
    "def simple_wavelet_transform(signal, sampling_rate, scaling_factor=0.25, wave_lowpass=None, wave_highpass=None):\n",
    "    \"\"\"\n",
    "    Simple wavelet transformation of signal\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : (N,1) array_like\n",
    "        Signal to be transformed\n",
    "    sampling_rate : int\n",
    "        Sampling rate of signal\n",
    "    scaling_factor : float, optional\n",
    "        Determines amount of log-space frequencies M in output, by default 0.25\n",
    "    wave_highpass : int, optional\n",
    "        Cut of frequencies below, by default 2\n",
    "    wave_lowpass : int, optional\n",
    "        Cut of frequencies above, by default 30000\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    wavelet_power : (N, M) array_like\n",
    "        Wavelet transformed signal\n",
    "    wavelet_frequencies : (M, 1) array_like\n",
    "        Corresponding frequencies to wavelet_power\n",
    "    wavelet_obj : object\n",
    "        WaveletTransform Object\n",
    "    \"\"\"\n",
    "    wavelet_obj = WaveletAnalysis(signal, dt=1 / sampling_rate, dj=scaling_factor)\n",
    "    wavelet_power = wavelet_obj.wavelet_power\n",
    "    wavelet_frequencies = wavelet_obj.fourier_frequencies\n",
    "\n",
    "    if wave_lowpass or wave_highpass:\n",
    "        wavelet_power = wavelet_power[(wavelet_frequencies < wave_lowpass) & (wavelet_frequencies > wave_highpass), :]\n",
    "        wavelet_frequencies = wavelet_frequencies[(\n",
    "            wavelet_frequencies < wave_lowpass) & (wavelet_frequencies > wave_highpass)]\n",
    "\n",
    "    return (wavelet_power, wavelet_frequencies, wavelet_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "#import deepinsight.util.wavelet_transform as wt\n",
    "\n",
    "\n",
    "def preprocess_input(fp_hdf_out, raw_data, average_window=1000, channels=None, window_size=100000,\n",
    "                     gap_size=50000, sampling_rate=30000, scaling_factor=0.5, num_cores=4):\n",
    "    \"\"\"\n",
    "    Transforms raw neural data to frequency space, via wavelet transform implemented currently with aaren-wavelets (https://github.com/aaren/wavelets)\n",
    "    Saves wavelet transformed data to HDF5 file (N, P, M) - (Number of timepoints, Number of frequencies, Number of channels)\n",
    "    Parameters\n",
    "    ----------\n",
    "    fp_hdf_out : str\n",
    "        File path to HDF5 file\n",
    "    raw_data : (N, M) file or array_like\n",
    "        Variable storing the raw_data (N data points, M channels), should allow indexing\n",
    "    average_window : int, optional\n",
    "        Average window to downsample wavelet transformed input, by default 1000\n",
    "    channels : array_like, optional\n",
    "        Which channels from raw_data to use, by default None\n",
    "    window_size : int, optional\n",
    "        Window size for calculating wavelet transformation, by default 100000\n",
    "    gap_size : int, optional\n",
    "        Gap size for calculating wavelet transformation, by default 50000\n",
    "    sampling_rate : int, optional\n",
    "        Sampling rate of raw_data, by default 30000\n",
    "    scaling_factor : float, optional\n",
    "        Determines amount of log-spaced frequencies P in output, by default 0.5\n",
    "    num_cores : int, optional\n",
    "        Number of paralell cores to use to calculate wavelet transformation, by default 4\n",
    "    \"\"\"\n",
    "    # Get number of chunks\n",
    "    if channels is None:\n",
    "        channels = np.arange(0, raw_data.shape[1])\n",
    "    num_points = raw_data.shape[0]\n",
    "    num_chunks = (num_points // gap_size) - 1\n",
    "    (_, wavelet_frequencies) = wavelet_transform(np.ones(window_size), sampling_rate, average_window, scaling_factor)\n",
    "    num_fourier_frequencies = len(wavelet_frequencies)\n",
    "\n",
    "    # Prepare output file\n",
    "    hdf5_file = h5py.File(fp_hdf_out, mode='a')\n",
    "    hdf5_file.create_dataset(\"inputs/wavelets\", [((num_chunks + 1) * gap_size) //\n",
    "                                                 average_window, num_fourier_frequencies, len(channels)], np.float32)\n",
    "    hdf5_file.create_dataset(\"inputs/fourier_frequencies\", [num_fourier_frequencies], np.float16)\n",
    "\n",
    "    # Prepare par pool\n",
    "    par = Parallel(n_jobs=num_cores, verbose=0)\n",
    "\n",
    "    # Start parallel wavelet transformation\n",
    "    print('Number of chunks {}'.format(num_chunks))\n",
    "    for c in range(0, num_chunks):\n",
    "        t_chunk = time.time()\n",
    "        print('Starting chunk {}'.format(c))\n",
    "\n",
    "        # Cut ephys\n",
    "        start = gap_size * c\n",
    "        end = start + window_size\n",
    "        print('Start {} - End {}'.format(start, end))\n",
    "        raw_chunk = raw_data[start: end, channels]\n",
    "\n",
    "        # Process raw chunk\n",
    "        raw_chunk = preprocess_chunk(raw_chunk, subtract_mean=True, convert_to_milivolt=False)\n",
    "\n",
    "        # Calculate wavelet transform\n",
    "        wavelet_transformed = np.zeros((raw_chunk.shape[0] // average_window, num_fourier_frequencies, len(channels)))\n",
    "        for ind, (wavelet_power, wavelet_frequencies) in enumerate(par(delayed(wavelet_transform)(raw_chunk[:, i], sampling_rate, average_window, scaling_factor) for i in range(0, len(channels)))):\n",
    "            wavelet_transformed[:, :, ind] = wavelet_power\n",
    "\n",
    "        # Save in output file\n",
    "        wavelet_index_end = end // average_window\n",
    "        wavelet_index_start = start // average_window\n",
    "        index_gap = gap_size // 2 // average_window\n",
    "        if c == 0:\n",
    "            this_index_start = 0\n",
    "            this_index_end = wavelet_index_end - index_gap\n",
    "            hdf5_file[\"inputs/wavelets\"][this_index_start:this_index_end,\n",
    "                                         :, :] = wavelet_transformed[0: -index_gap, :, :]\n",
    "        elif c == num_chunks - 1:  # Make sure the last one fits fully\n",
    "            this_index_start = wavelet_index_start + index_gap\n",
    "            this_index_end = wavelet_index_end\n",
    "            hdf5_file[\"inputs/wavelets\"][this_index_start:this_index_end, :, :] = wavelet_transformed[index_gap::, :, :]\n",
    "\n",
    "        else:\n",
    "            this_index_start = wavelet_index_start + index_gap\n",
    "            this_index_end = wavelet_index_end - index_gap\n",
    "            hdf5_file[\"inputs/wavelets\"][this_index_start:this_index_end,\n",
    "                                         :, :] = wavelet_transformed[index_gap: -index_gap, :, :]\n",
    "        hdf5_file.flush()\n",
    "        print('This chunk time {}'.format(time.time() - t_chunk))\n",
    "\n",
    "    # 7.) Put frequencies in and close file\n",
    "    hdf5_file[\"inputs/fourier_frequencies\"][:] = wavelet_frequencies\n",
    "    hdf5_file.flush()\n",
    "    hdf5_file.close()\n",
    "\n",
    "\n",
    "def preprocess_chunk(raw_chunk, subtract_mean=True, convert_to_milivolt=False):\n",
    "    \"\"\"\n",
    "    Preprocesses a chunk of data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_chunk : array_like\n",
    "        Chunk of raw_data to preprocess\n",
    "    subtract_mean : bool, optional\n",
    "        Subtract mean over all other channels, by default True\n",
    "    convert_to_milivolt : bool, optional\n",
    "        Convert chunk to milivolt , by default False\n",
    "    Returns\n",
    "    -------\n",
    "    raw_chunk : array_like\n",
    "        preprocessed_chunk\n",
    "    \"\"\"\n",
    "    # Subtract mean across all channels\n",
    "    if subtract_mean:\n",
    "        raw_chunk = raw_chunk.transpose() - np.mean(raw_chunk.transpose(), axis=0)\n",
    "        raw_chunk = raw_chunk.transpose()\n",
    "    # Convert to milivolt\n",
    "    if convert_to_milivolt:\n",
    "        raw_chunk = raw_chunk * (0.195 / 1000)\n",
    "    return raw_chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1924b2000286>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/media/maria/DATA1/Documents/DeepInsightAn'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-70450c95c5dd>\u001b[0m in \u001b[0;36mpreprocess_input\u001b[0;34m(fp_hdf_out, raw_data, average_window, channels, window_size, gap_size, sampling_rate, scaling_factor, num_cores)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mnum_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mnum_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_points\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mgap_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwavelet_frequencies\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwavelet_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaling_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mnum_fourier_frequencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwavelet_frequencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wt' is not defined"
     ]
    }
   ],
   "source": [
    "path='/media/maria/DATA1/Documents/DeepInsightAn'\n",
    "preprocess_input(path,S.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
