{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data matrix, neurons by timepoints: (18795, 30766)\n",
      "(18795, 30560)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "data_path='/media/maria/DATA1/Documents/data_for_suite2p/TX39/'\n",
    "dt=1\n",
    "spks= np.load(data_path+'spks.npy')\n",
    "print('Shape of the data matrix, neurons by timepoints:',spks.shape)\n",
    "iframe = np.load(data_path+'iframe.npy') # iframe[n] is the microscope frame for the image frame n\n",
    "ivalid = iframe+dt<spks.shape[-1] # remove timepoints outside the valid time range\n",
    "iframe = iframe[ivalid]\n",
    "S = spks[:, iframe+dt]\n",
    "print(S.shape)\n",
    "S=zscore(S,axis=1)\n",
    "proc = np.load(data_path+'cam1_TX39_2019_05_31_1_proc_resampled.npy', allow_pickle=True).item()\n",
    "motSVD = proc['motSVD'][:,iframe+dt]\n",
    "motSVD -= motSVD.mean(axis=1)[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 30560)\n"
     ]
    }
   ],
   "source": [
    "print(motSVD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/anaconda3/lib/python3.7/site-packages/wavelets/transform.py:104: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  wavelet_data[slices],\n"
     ]
    }
   ],
   "source": [
    "from wavelets import WaveletAnalysis\n",
    "\n",
    "# given a signal x(t)\n",
    "x =S[0,:]\n",
    "# and a sample spacing\n",
    "dt = 0.25\n",
    "\n",
    "wa = WaveletAnalysis(x, dt=dt)\n",
    "\n",
    "# wavelet power spectrum\n",
    "power = wa.wavelet_power\n",
    "\n",
    "# scales \n",
    "scales = wa.scales\n",
    "\n",
    "# associated time vector\n",
    "t = wa.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 30560)\n"
     ]
    }
   ],
   "source": [
    "print(power.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f41a81d3c10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multivariate cnn example\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    " \n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    " \n",
    "# define input sequence\n",
    "in_seq1 = power[0,0:1000]\n",
    "in_seq2 = power[1,0:1000]\n",
    "out_seq = motSVD[0,:1000]\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "n_features = X.shape[2]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=1000, verbose=0)\n",
    "# demonstrate prediction\n",
    "#x_input = array([[80, 85], [90, 95], [100, 105]])\n",
    "#x_input = x_input.reshape((1, n_steps, n_features))\n",
    "#yhat = model.predict(x_input, verbose=0)\n",
    "#print(yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
